{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "# Parte B\n",
    "\n",
    "'Data splitting' e métricas de exatidão em ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "def tt(x, y, test_size):\n",
    "    test_size = test_size*0.01\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=1)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def tvt(X, y, test_size, val_size):\n",
    "    test_size = test_size*0.01\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=1)\n",
    "\n",
    "    val_size = (val_size*0.01)/test_size\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_size, random_state=1) # 0.25 x 0.8 = 0.2\n",
    "    return X_train, X_test, y_train, y_test, X_val, y_val\n",
    "\n",
    "def k_fold(X, splits):\n",
    "    kf = KFold(n_splits=splits)\n",
    "    X_test=[]\n",
    "    X_train=[]\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "        X_train.append(train_index)\n",
    "        X_test.append(test_index)\n",
    "    return X_train, X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "\n",
    "def confusion(knn, y_test, y_pred):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    matrix = plot_confusion_matrix(knn, X_test, y_test, cmap=plt.cm.Blues)\n",
    "    matrix.ax_.set_title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.gcf().axes[0]\n",
    "    plt.gcf().axes[1]\n",
    "    return cm, plt\n",
    "\n",
    "def exact_methods(y_true, y_pred, av):\n",
    "    '''\n",
    "    av = micro\n",
    "    av = macro\n",
    "    av = binary\n",
    "    av = samples\n",
    "    av = weighted\n",
    "    '''\n",
    "    recall = recall_score(y_true, y_pred, average=av) # average=?\n",
    "    precision = precision_score(y_true, y_pred, average=av)\n",
    "    f1 = f1_score(y_true, y_pred, average=av)\n",
    "    return recall, precision, f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentar com o knn\n",
    "\n",
    "Como na primeira função implementamos já o knn para o plot, experimentamos com 'dummy_data' apenas para a segunda função"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333 0.2222222222222222 0.26666666666666666\n"
     ]
    }
   ],
   "source": [
    "dummy_real = [0, 1, 2, 0, 1, 2]\n",
    "dummy_pred = [0, 2, 1, 0, 0, 1]\n",
    "\n",
    "recall, precision, f1 = exact_methods(dummy_real, dummy_pred, 'macro')\n",
    "print(recall, precision, f1) # com average = 'micro' os resultados sao iguais\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Eduardo\\Documents\\MECD\\TCD\\TCD-TL\\TCD-TL\\mainActivity_partB.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Eduardo/Documents/MECD/TCD/TCD-TL/TCD-TL/mainActivity_partB.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mneighbors\u001b[39;00m \u001b[39mimport\u001b[39;00m KNeighborsClassifier\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Eduardo/Documents/MECD/TCD/TCD-TL/TCD-TL/mainActivity_partB.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m knn \u001b[39m=\u001b[39m KNeighborsClassifier(n_neighbors\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Eduardo/Documents/MECD/TCD/TCD-TL/TCD-TL/mainActivity_partB.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m knn\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Eduardo/Documents/MECD/TCD/TCD-TL/TCD-TL/mainActivity_partB.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m y_pred \u001b[39m=\u001b[39m knn\u001b[39m.\u001b[39mpredict(X_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=8)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "df = pd.DataFrame(iris.data, columns = iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.93333333 1.         1.         0.86666667 0.93333333\n",
      " 0.93333333 1.         1.         1.        ]\n",
      "cv_scores mean:0.9666666666666668\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = tt(X, y, 0.5)\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train) #train\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "acc = knn.score(X_test, y_test) #test\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "knn_cv = KNeighborsClassifier(n_neighbors=6)\n",
    "#train model with cv of 5 \n",
    "cv_scores = cross_val_score(knn_cv, X, y, cv=10)\n",
    "#print each cv score (accuracy) and average them\n",
    "print(cv_scores)\n",
    "print('cv_scores mean:{}'.format(np.mean(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbours = np.linspace(1, 15, 8)\n",
    "\n",
    "for n in neighbours:\n",
    "    knn = KNeighborsClassifier(n_neighbors=int(n))\n",
    "    knn.fit(X, y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = np.linspace(1, 15, 8)\n",
    "print(neigh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TT, TVT e nCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def tt(X, y, test_size):\n",
    "\n",
    "def cross_validation(train_X, train_y, num_folds=10, k=1):\n",
    "    dataset = list()\n",
    "    dataset_split = list()\n",
    "    val_acc = list()\n",
    "    \n",
    "    for i in range(len(train_X)):\n",
    "        data = np.append(train_X[i],train_y[i])\n",
    "        dataset.append(data)\n",
    "    \n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset) / num_folds)\n",
    "    \n",
    "    for i in range(num_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "        \n",
    "    for folds in dataset_split:\n",
    "        train_set= folds\n",
    "        train_set = np.array(train_set)\n",
    "        test_set = list()\n",
    "        for row in folds:\n",
    "            row_copy = list(row)\n",
    "            test_set.append(row_copy)\n",
    "            row_copy[-1] = None\n",
    "        test_set = np.array(test_set)\n",
    "        train_x = train_set[:, :-1]\n",
    "        train_y = train_set[:,-1]\n",
    "        test_x = test_set[:, :-1]\n",
    "        predicted = predict(train_x,train_y, test_x, k)\n",
    "        actual = [row[-1] for row in fold]\n",
    "        accuracy = compute_accuracy(actual, predicted)\n",
    "        val_acc.append(accuracy)\n",
    "        \n",
    "    val_acc_var = statistics.variance(val_acc)\n",
    "    vall_acc = sum(val_acc)/len(val_acc)\n",
    "\n",
    "    return vall_acc, val_acc_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sobre overfitting\n",
    "\n",
    "Overfitting refers to an unwanted behavior of a machine learning algorithm used for predictive modeling.\n",
    "\n",
    "It is the case where model performance on the training dataset is improved at the cost of worse performance on data not seen during training, such as a holdout test dataset or new data.\n",
    "\n",
    "We can identify if a machine learning model has overfit by first evaluating the model on the training dataset and then evaluating the same model on a holdout test dataset.\n",
    "\n",
    "If the performance of the model on the training dataset is significantly better than the performance on the test dataset, then the model may have overfit the training dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usar as features dadas pelo Relief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbours = 5\n",
    "x_relief = relief(X, y, neighbours, 10) # TODO qual o numero de features que se quer\n",
    "# TODO tem que se alterar o algoritmo de relief?\n",
    "print(x_relief.shape, y.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_relief, y, test_size=0.3, random_state=1)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(X_train, y_train) #train\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "f1_score(y_pred, y_test, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate = []# Will take some time\n",
    "for i in range(1, X_train.shape[1]+1):\n",
    "    print(i)\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    pred_i = knn.predict(X_test)\n",
    "    error_rate.append(np.mean(pred_i != y_test))\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,X_train.shape[1]+1),error_rate,color='blue', linestyle='dashed', marker='o',\n",
    " markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Análise ao *dataset* original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = []\n",
    "\n",
    "for i in range (0,15):\n",
    "    loc.append(\"FORTH_TRACE_DATASET-master/part\" + str(i) + \"/part\" + str(i) + \"dev2.csv\")\n",
    "\n",
    "array = []\n",
    "for file in loc:\n",
    "    df = pd.read_csv(file, sep=',', header=None)\n",
    "    array.append(df.to_numpy())\n",
    "\n",
    "array = np.concatenate(array)\n",
    "print(array.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "451f9409e4a1d80d0e57066b36b4624c2c0f11dfc98b1c0bd8da4a3c0fa8d9f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
