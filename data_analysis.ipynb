{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Column1: Device ID\n",
    "- Column2: accelerometer x\n",
    "- Column3: accelerometer y\n",
    "- Column4: accelerometer z\n",
    "- Column5: gyroscope x\n",
    "- Column6: gyroscope y\n",
    "- Column7: gyroscope z\n",
    "- Column8: magnetometer x\n",
    "- Column9: magnetometer y\n",
    "- Column10: magnetometer z\n",
    "- Column11: Timestamp\n",
    "- Column12: Activity Label (16 atividades)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ReliefF import ReliefF\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "import mainActivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Carregamento e preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 20 # TODO tirar isto daqui\n",
    "loc = []\n",
    "\n",
    "for i in range (0,15):\n",
    "    loc.append(\"FORTH_TRACE_DATASET-master/part\" + str(i) + \"/part\" + str(i) + \"dev2.csv\")\n",
    "\n",
    "array = []\n",
    "for file in loc:\n",
    "    df = pd.read_csv(file, sep=',', header=None)\n",
    "    print(df.shape)\n",
    "    array.append(df.to_numpy())\n",
    "\n",
    "array = np.concatenate(array)\n",
    "print(array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Análise e tratamento de *Outliers*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t_acc = np.sqrt(np.add(np.square(array[:,1]),\n",
    "                       np.square(array[:,2]),\n",
    "                       np.square(array[:,3])))\n",
    "\n",
    "t_gyr = np.sqrt(np.add(np.square(array[:,4]),\n",
    "                       np.square(array[:,5]),\n",
    "                       np.square(array[:,6])))\n",
    "\n",
    "t_mag = np.sqrt(np.add(np.square(array[:,7]),\n",
    "                       np.square(array[:,8]),\n",
    "                       np.square(array[:,9])))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 boxplot de cada atividade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# act1 = t_acc[array[:,-1]==5]\n",
    "activities = np.arange(1, 17) \n",
    "box_acc = [] # TODO ver se dá para fazer isto com np.array\n",
    "box_gyr = []\n",
    "box_mag = []\n",
    "for i in range(1,17):\n",
    "    act = (array[:,-1]==i)\n",
    "    #length = np.sum(act)\n",
    "    box_acc.append(t_acc[act]) \n",
    "    box_gyr.append(t_gyr[act])\n",
    "    box_mag.append(t_mag[act])\n",
    "\n",
    "#box_acc = np.array(box_acc)\n",
    "plt.figure()\n",
    "fig, axs = plt.subplots(3)\n",
    "axs[0].boxplot(box_acc)\n",
    "axs[1].boxplot(box_gyr)\n",
    "axs[2].boxplot(box_mag)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zscores, outliersk = mainActivity.zscore(t_acc, 3)\n",
    "print(zscores.shape, outliersk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# desvio e outliers para cada k = 3, 3.5, 4\n",
    "d = np.empty(shape=[3,16])\n",
    "outliersk = np.empty(shape=[])\n",
    "x_density = 5 # percentage\n",
    "it = 0\n",
    "\n",
    "# iterar pelos modulos e, depois, por cada atividade\n",
    "for box in ([box_acc, box_gyr, box_mag]):\n",
    "    \n",
    "    for i in range(16):\n",
    "        # computar os quartis e definir os limites\n",
    "        q1 = np.quantile(box[:][i], 0.25)\n",
    "        q3 = np.quantile(box[:][i], 0.75)\n",
    "        iqr = q3-q1 # interquartile range\n",
    "        upper_bound = q3+(1.5*iqr)\n",
    "        lower_bound = q1-(1.5*iqr)\n",
    "\n",
    "        # receber os outliers e a matrix de indices dos mesmos\n",
    "        outliers = box[:][i][(box[:][i] <= lower_bound) | (box[:][i] >= upper_bound)]\n",
    "        out_bool = (box[:][i] <= lower_bound) | (box[:][i] >= upper_bound)\n",
    "        box[:][i] = box[:][i][(box[:][i] >= lower_bound) & (box[:][i] <= upper_bound)]\n",
    "        print(outliers)\n",
    "        \n",
    "        #unique, counts = np.unique(out_bool, return_counts=True)\n",
    "        #desvios\n",
    "        counts = np.count_nonzero(out_bool==True)\n",
    "        d[it][i] = (counts/out_bool.size)*100 \n",
    "        \n",
    "        # TODO breakar aqui provavelmente, ler melhor se e mesmo para\n",
    "        # TODO ver melhor porque deve estar mal, ver a formula mat mesmo\n",
    "        # implementar o z-score a cada coluna\n",
    "        zscores, outliersk = mainActivity.zscore(box[:][i], 3)\n",
    "        zscores, outliersk = mainActivity.zscore(box[:][i], 3.5)\n",
    "        zscores, outliersk = mainActivity.zscore(box[:][i], 4)\n",
    "        \n",
    "        #iterar para cada coluna\n",
    "        # TODO verificar isto, comparar com o z-score, plotar (acc, gyr, mag)\n",
    "        centroids, cluster = mainActivity.k_means(box[:][i], 3)\n",
    "    it += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = t_acc[50:250]\n",
    "\n",
    "a, b = mainActivity.get_outliers(n)\n",
    "print()\n",
    "\n",
    "c = mainActivity.inject_outliers(5, b, n, 0.5)\n",
    "\n",
    "print(n, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_out, td = mainActivity.get_outliers(t_acc)\n",
    "p = t_out.shape[0]\n",
    "t_outliers = mainActivity.inject_outliers(10, 4, t_out.copy(), p)\n",
    "# TODO verificar se isto da mesmo certo, arrays diferentes para verificar mesmo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = []\n",
    "for vec in box_acc:\n",
    "    \n",
    "    n = vec.size    \n",
    "    ran = np.ptp(vec)\n",
    "    test = np.random.rand(n)*ran\n",
    "    #print(np.reshape(test[:n], (-1,1)))\n",
    "    #print(np.reshape(vec[:n], (-1,1)).shape)\n",
    "    test = np.append(test[:n], test[:n]).reshape(-1, 2)\n",
    "    coef.append(mainActivity.fit_linear(test, vec, n))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(16):\n",
    "    stats.kstest(box_acc[:][i], 'norm') # if follows a gaussian\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Features**\n",
    "\n",
    "No artigo em causa, as features estatísticas direcionam-se apenas a cada eixo do acelerómetro e do giroscópio (colunas 1-7)\n",
    "\n",
    "Damos também uso A estratégia 'sliding window' para atuar em todo o array de forma contínua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = mainActivity.mean(array[:,1:7], window)\n",
    "median = mainActivity.median(array[:,1:7], window)\n",
    "std, var = mainActivity.std_var(array[:,1:7], window)\n",
    "rms = mainActivity.rms(array[:,1:7], window)\n",
    "irange = mainActivity.irange(array[:,1:7], window)\n",
    "\n",
    "ai, vi = mainActivity.mov_intensity(array[:,1:4], window)\n",
    "sma = mainActivity.sma(array[:,1:4], window)\n",
    "\n",
    "ai.shape\n",
    "feat_array = np.concatenate((mean, median, std, var, rms, irange), \\\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = array[:,1:10]\n",
    "y = array[:,-1]\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = array[:,1:10]\n",
    "y = array[:,-1]\n",
    "\n",
    "pca, X_train, X_test, y_train, y_test = mainActivity.pca_feature(x, y, 0.5)\n",
    "\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "var = pca.explained_variance_ratio_\n",
    "print(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from skfeature.function.similarity_based import fisher_score \n",
    "\n",
    "ranks = fisher_score.fisher_score(x, y)\n",
    "\n",
    "fisher_score.feature_rating\n",
    "\n",
    "\n",
    "nao esta a dar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relief(x, y, neighbours, feat):\n",
    "      \n",
    "      fs = ReliefF(n_neighbors=1, n_features_to_keep=10)\n",
    "      X_train = fs.fit_transform(x, y)\n",
    "      return X_train\n",
    "\n",
    "X_train = relief(feat_array, y, 5, 10)\n",
    "print(X_train)\n",
    "print(\"--------------\")\n",
    "print(\"(No. of tuples, No. of Columns before ReliefF) : \"+str(feat_array.shape)+\n",
    "      \"\\n(No. of tuples , No. of Columns after ReliefF) : \"+str(X_train.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "# Parte B\n",
    "\n",
    "'Data splitting' e métricas de exatidão em ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO passar para função !!!!!\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "x = array[:,1:10]\n",
    "y = array[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y)\n",
    "\n",
    "\n",
    "splits = 4 # split in n equal parts\n",
    "kf = KFold(n_splits=splits)\n",
    "\n",
    "for train_index, test_index in kf.split(x):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "\n",
    "def confusion(knn, y_test, y_pred):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    matrix = plot_confusion_matrix(knn, X_test, y_test, cmap=plt.cm.Blues)\n",
    "    matrix.ax_.set_title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.gcf().axes[0]\n",
    "    plt.gcf().axes[1]\n",
    "    return cm, plt\n",
    "\n",
    "def exact_methods(y_true, y_pred, av):\n",
    "    '''\n",
    "    av = micro\n",
    "    av = macro\n",
    "    av = binary\n",
    "    av = samples\n",
    "    av = weighted\n",
    "    '''\n",
    "    recall = recall_score(y_true, y_pred, average=av) # average=?\n",
    "    precision = precision_score(y_true, y_pred, average=av)\n",
    "    f1 = f1_score(y_true, y_pred, average=av)\n",
    "    return recall, precision, f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentar com o knn\n",
    "\n",
    "Como na primeira função implementamos já o knn para o plot, experimentamos com 'dummy_data' apenas para a segunda função"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_real = [0, 1, 2, 0, 1, 2]\n",
    "dummy_pred = [0, 2, 1, 0, 0, 1]\n",
    "\n",
    "recall, precision, f1 = exact_methods(dummy_real, dummy_pred, 'macro')\n",
    "print(recall, precision, f1) # com average = 'micro' os resultados sao iguais\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=8)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "df = pd.DataFrame(iris.data, columns = iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train) #train\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "acc = knn.score(X_test, y_test) #test\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "knn_cv = KNeighborsClassifier(n_neighbors=6)\n",
    "#train model with cv of 5 \n",
    "cv_scores = cross_val_score(knn_cv, X, y, cv=10)\n",
    "#print each cv score (accuracy) and average them\n",
    "print(cv_scores)\n",
    "print('cv_scores mean:{}'.format(np.mean(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbours = np.linspace(1, 15, 8)\n",
    "\n",
    "for n in neighbours:\n",
    "    knn = KNeighborsClassifier(n_neighbors=int(n))\n",
    "    knn.fit(X, y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = np.linspace(1, 15, 8)\n",
    "print(neigh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TT, TVT e nCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#def tt(X, y, test_size):\n",
    "    \n",
    "def tvt(X, y, test_size, val_size):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=1)\n",
    "\n",
    "    val_size = val_size/test_size\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_size, random_state=1) # 0.25 x 0.8 = 0.2\n",
    "    return X_train, X_test, \n",
    "\n",
    "def cross_validation(train_X, train_y, num_folds=10, k=1):\n",
    "    dataset = list()\n",
    "    dataset_split = list()\n",
    "    val_acc = list()\n",
    "    \n",
    "    for i in range(len(train_X)):\n",
    "        data = np.append(train_X[i],train_y[i])\n",
    "        dataset.append(data)\n",
    "    \n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset) / num_folds)\n",
    "    \n",
    "    for i in range(num_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "        \n",
    "    for folds in dataset_split:\n",
    "        train_set= folds\n",
    "        train_set = np.array(train_set)\n",
    "        test_set = list()\n",
    "        for row in folds:\n",
    "            row_copy = list(row)\n",
    "            test_set.append(row_copy)\n",
    "            row_copy[-1] = None\n",
    "        test_set = np.array(test_set)\n",
    "        train_x = train_set[:, :-1]\n",
    "        train_y = train_set[:,-1]\n",
    "        test_x = test_set[:, :-1]\n",
    "        predicted = predict(train_x,train_y, test_x, k)\n",
    "        actual = [row[-1] for row in fold]\n",
    "        accuracy = compute_accuracy(actual, predicted)\n",
    "        val_acc.append(accuracy)\n",
    "        \n",
    "    val_acc_var = statistics.variance(val_acc)\n",
    "    vall_acc = sum(val_acc)/len(val_acc)\n",
    "\n",
    "    return vall_acc, val_acc_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sobre overfitting\n",
    "\n",
    "Overfitting refers to an unwanted behavior of a machine learning algorithm used for predictive modeling.\n",
    "\n",
    "It is the case where model performance on the training dataset is improved at the cost of worse performance on data not seen during training, such as a holdout test dataset or new data.\n",
    "\n",
    "We can identify if a machine learning model has overfit by first evaluating the model on the training dataset and then evaluating the same model on a holdout test dataset.\n",
    "\n",
    "If the performance of the model on the training dataset is significantly better than the performance on the test dataset, then the model may have overfit the training dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bias_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usar as features dadas pelo Relief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbours = 5\n",
    "x_relief = relief(X, y, neighbours, 10) # TODO qual o numero de features que se quer\n",
    "# TODO tem que se alterar o algoritmo de relief?\n",
    "print(x_relief.shape, y.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_relief, y, test_size=0.3, random_state=1)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(X_train, y_train) #train\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "f1_score(y_pred, y_test, average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Gráfico de cotovelo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "error_rate = []# Will take some time\n",
    "for i in range(1, X_train.shape[1]+1):\n",
    "    print(i)\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    pred_i = knn.predict(X_test)\n",
    "    error_rate.append(np.mean(pred_i != y_test))\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,X_train.shape[1]+1),error_rate,color='blue', linestyle='dashed', marker='o',\n",
    " markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c5abe1dd6f168b4f5e67de02cffc00ce8cef82ade2b382edc6fecc892b15c5a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
